{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "11iMyg72Th9n1vFLDbmn6HDyLl__uxQzp",
      "authorship_tag": "ABX9TyNqZnTzNlVopDm/JaesmGes",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/montatriki/ICCME2024/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "I8KK99z31OS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214181fc-57c8-41a0-8995-3d1b2336f669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  faiss_index.index  model.pt  products.json  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1E2xRgfzQv9"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "!pip install -q transformers faiss-cpu faiss-gpu torch\n",
        "!pip install -q sentence-transformers nltk unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from typing import List, Dict\n",
        "import time"
      ],
      "metadata": {
        "id": "dS0t24KKzh2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Configuration\n",
        "class Config:\n",
        "    MODEL_NAME = 'dbmdz/bert-base-turkish-cased'\n",
        "    MAX_LENGTH = 128\n",
        "    BATCH_SIZE = 32  # Reduced batch size for stability\n",
        "    EPOCHS = 5\n",
        "    LEARNING_RATE = 2e-5\n",
        "    EMBEDDING_DIM = 768\n",
        "    SAVE_PATH = '/content/drive/MyDrive/product_search_model'\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = Config()\n",
        "print(f\"Using device: {config.DEVICE}\")\n"
      ],
      "metadata": {
        "id": "wlJGNotmzmI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b834378-3e38-4e68-97b4-a2f042c7669f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Dataset Class with Fixed Device Handling\n",
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, products, tokenizer, max_length=128):\n",
        "        self.products = products\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.category_to_products = self._group_by_category()\n",
        "\n",
        "    def _group_by_category(self):\n",
        "        category_dict = {}\n",
        "        for product in self.products:\n",
        "            category = product['product_category']\n",
        "            if category not in category_dict:\n",
        "                category_dict[category] = []\n",
        "            category_dict[category].append(product)\n",
        "        return category_dict\n",
        "\n",
        "    def _normalize_text(self, text):\n",
        "        text = text.lower().strip()\n",
        "        text = re.sub(r'[^a-zğüşıöçA-ZĞÜŞİÖÇ0-9\\s]', ' ', text)\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.products)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        product = self.products[idx]\n",
        "        category = product['product_category']\n",
        "\n",
        "        # Get same category product\n",
        "        same_category_products = [p for p in self.category_to_products[category] if p['id'] != product['id']]\n",
        "        if same_category_products:\n",
        "            positive_product = np.random.choice(same_category_products)\n",
        "        else:\n",
        "            positive_product = product\n",
        "\n",
        "        # Get different category product\n",
        "        other_categories = [c for c in self.category_to_products.keys() if c != category]\n",
        "        if other_categories:\n",
        "            neg_category = np.random.choice(other_categories)\n",
        "            negative_product = np.random.choice(self.category_to_products[neg_category])\n",
        "        else:\n",
        "            negative_product = product\n",
        "\n",
        "        # Create texts\n",
        "        anchor_text = f\"{product['brand']} {product['master_data_name']} {category}\"\n",
        "        positive_text = f\"{positive_product['brand']} {positive_product['master_data_name']} {category}\"\n",
        "        negative_text = f\"{negative_product['brand']} {negative_product['master_data_name']} {neg_category}\"\n",
        "\n",
        "        # Tokenize\n",
        "        encoding = self.tokenizer(\n",
        "            [self._normalize_text(anchor_text),\n",
        "             self._normalize_text(positive_text),\n",
        "             self._normalize_text(negative_text)],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'],\n",
        "            'attention_mask': encoding['attention_mask'],\n",
        "            'product_id': product['id']\n",
        "        }"
      ],
      "metadata": {
        "id": "P-RONWvhzobO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Model Definition\n",
        "class ProductSearchModel(nn.Module):\n",
        "    def __init__(self, bert_model_name: str, embedding_dim: int = 768):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.product_embedding = nn.Linear(768, embedding_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        embeddings = self.product_embedding(pooled_output)\n",
        "        return torch.nn.functional.normalize(embeddings, p=2, dim=1)\n"
      ],
      "metadata": {
        "id": "TBTIAFIQzuOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Training Function\n",
        "def train_model(model, dataset, config):\n",
        "    model = model.to(config.DEVICE)\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
        "    criterion = nn.TripletMarginLoss(margin=0.5)\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{config.EPOCHS}')\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(config.DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(config.DEVICE)\n",
        "\n",
        "            # Get embeddings for anchor, positive, and negative\n",
        "            all_embeddings = model(input_ids.view(-1, input_ids.size(-1)),\n",
        "                                 attention_mask.view(-1, attention_mask.size(-1)))\n",
        "\n",
        "            # Reshape embeddings\n",
        "            anchor = all_embeddings[0::3]\n",
        "            positive = all_embeddings[1::3]\n",
        "            negative = all_embeddings[2::3]\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(anchor, positive, negative)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, f'{config.SAVE_PATH}_epoch_{epoch+1}.pt')\n"
      ],
      "metadata": {
        "id": "h0vTKjedzv76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Initialize and Train\n",
        "print(\"Loading data...\")\n",
        "with open('products.json', 'r', encoding='utf-8') as f:\n",
        "    products = json.load(f)\n",
        "\n",
        "print(\"Initializing model and tokenizer...\")\n",
        "model = ProductSearchModel(config.MODEL_NAME, config.EMBEDDING_DIM)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
        "dataset = ProductDataset(products, tokenizer, config.MAX_LENGTH)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "train_model(model, dataset, config)"
      ],
      "metadata": {
        "id": "as9FHJ78zyWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53d4cfc-d8ea-4f5a-c24e-ad55d450b6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Initializing model and tokenizer...\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 237/237 [06:46<00:00,  1.72s/it, loss=0.0254]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.0511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 237/237 [06:57<00:00,  1.76s/it, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 0.0073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 237/237 [06:56<00:00,  1.76s/it, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 0.0035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 237/237 [06:55<00:00,  1.76s/it, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 0.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 237/237 [06:55<00:00,  1.75s/it, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Average Loss: 0.0027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Fixed Search Engine Implementation\n",
        "class ProductSearchEngine:\n",
        "    def __init__(self, model, tokenizer, config, products):\n",
        "        self.model = model.to(config.DEVICE)\n",
        "        self.model.eval()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config\n",
        "\n",
        "        # Initialize FAISS\n",
        "        self.dimension = config.EMBEDDING_DIM\n",
        "        self.index = faiss.IndexFlatIP(self.dimension)\n",
        "\n",
        "        # Store product info\n",
        "        self.products_cache = {i: product for i, product in enumerate(products)}\n",
        "        self._build_index(products)\n",
        "\n",
        "    def _normalize_text(self, text: str) -> str:\n",
        "        text = text.lower().strip()\n",
        "        text = re.sub(r'[^a-zğüşıöçA-ZĞÜŞİÖÇ0-9\\s]', ' ', text)\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def _build_index(self, products):\n",
        "        print(\"Building search index...\")\n",
        "        batch_size = 64\n",
        "        embeddings = []\n",
        "\n",
        "        for i in tqdm(range(0, len(products), batch_size)):\n",
        "            batch = products[i:i + batch_size]\n",
        "            texts = [\n",
        "                f\"{p['brand']} {p['master_data_name']} {p['product_category']}\"\n",
        "                for p in batch\n",
        "            ]\n",
        "            texts = [self._normalize_text(t) for t in texts]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                encoded = self.tokenizer(\n",
        "                    texts,\n",
        "                    padding=True,\n",
        "                    truncation=True,\n",
        "                    max_length=self.config.MAX_LENGTH,\n",
        "                    return_tensors='pt'\n",
        "                )\n",
        "\n",
        "                # Move to device and only pass input_ids and attention_mask\n",
        "                input_ids = encoded['input_ids'].to(self.config.DEVICE)\n",
        "                attention_mask = encoded['attention_mask'].to(self.config.DEVICE)\n",
        "\n",
        "                # Get embeddings\n",
        "                batch_embeddings = self.model(input_ids, attention_mask).cpu().numpy()\n",
        "                embeddings.append(batch_embeddings)\n",
        "\n",
        "        # Combine all embeddings\n",
        "        embeddings = np.vstack(embeddings)\n",
        "\n",
        "        # Add to index\n",
        "        self.index.add(embeddings)\n",
        "        print(f\"Index built with {len(products)} products\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 5):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Preprocess query\n",
        "        query = self._normalize_text(query)\n",
        "\n",
        "        # Encode query\n",
        "        with torch.no_grad():\n",
        "            encoded = self.tokenizer(\n",
        "                query,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=self.config.MAX_LENGTH,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Move to device and only pass input_ids and attention_mask\n",
        "            input_ids = encoded['input_ids'].to(self.config.DEVICE)\n",
        "            attention_mask = encoded['attention_mask'].to(self.config.DEVICE)\n",
        "\n",
        "            # Get query embedding\n",
        "            query_embedding = self.model(input_ids, attention_mask).cpu().numpy()\n",
        "\n",
        "        # Search\n",
        "        distances, indices = self.index.search(query_embedding, top_k)\n",
        "\n",
        "        # Prepare results\n",
        "        results = []\n",
        "        for i, idx in enumerate(indices[0]):\n",
        "            if idx != -1:\n",
        "                product = self.products_cache[idx]\n",
        "                results.append({\n",
        "                    'id': product['id'],\n",
        "                    'master_data_name': product['master_data_name'],\n",
        "                    'brand': product['brand'],\n",
        "                    'category': product['product_category'],\n",
        "                    'similarity_score': float(distances[0][i])\n",
        "                })\n",
        "\n",
        "        return {\n",
        "            'results': results,\n",
        "            'metadata': {\n",
        "                'query_time_ms': round((time.time() - start_time) * 1000, 2),\n",
        "                'processed_query': query\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "cQNsxI3Tz67p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Initialize and Test Search Engine\n",
        "print(\"Initializing search engine...\")\n",
        "search_engine = ProductSearchEngine(model, tokenizer, config, products)\n",
        "\n",
        "# Test queries\n",
        "test_queries = [\n",
        "    \"iphone telefon arıyorum\",\n",
        "    \"kablosuz kulaklik bluetooth\",\n",
        "    \"samsung tv 4k\",\n",
        "    \"tablet için şarj aleti\"\n",
        "]\n",
        "\n",
        "print(\"\\nTesting search functionality:\")\n",
        "for query in test_queries:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    results = search_engine.search(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdmDo-ERz82H",
        "outputId": "b10cb924-3b37-4b2d-fbd3-1cbdcab3cf45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing search engine...\n",
            "Building search index...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [00:18<00:00,  6.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index built with 7579 products\n",
            "\n",
            "Testing search functionality:\n",
            "\n",
            "Query: iphone telefon arıyorum\n",
            "\n",
            "Query: kablosuz kulaklik bluetooth\n",
            "\n",
            "Query: samsung tv 4k\n",
            "\n",
            "Query: tablet için şarj aleti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Save Components\n",
        "model_path, index_path = save_all_components(model, search_engine, config)"
      ],
      "metadata": {
        "id": "W-FKjiBS0Jyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b976db-f3db-4f6f-bf1b-fecbad8fc627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to: /content/drive/MyDrive/product_search/model_20241222_1457.pt\n",
            "Saved index to: /content/drive/MyDrive/product_search/faiss_index_20241222_1457.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Test a few more complex queries\n",
        "complex_queries = [\n",
        "    \"evime yeni bir televizyon sistemi arıyorum ses kalitesi iyi olsun\",\n",
        "    \"telefon sarj aleti type c\",\n",
        "    \"gaming mouse rgb ışıklı\",\n",
        "    \"bluetooth hoparlör taşınabilir\"\n",
        "]\n",
        "\n",
        "print(\"\\nTesting complex queries:\")\n",
        "for query in complex_queries:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    results = search_engine.search(query)\n",
        "    for result in results['results']:\n",
        "        print(f\"- {result['brand']} {result['master_data_name']} (Score: {result['similarity_score']:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnD35dvT0Nli",
        "outputId": "f29de8ec-9fcb-44fe-f616-312c955d78b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing complex queries:\n",
            "\n",
            "Query: evime yeni bir televizyon sistemi arıyorum ses kalitesi iyi olsun\n",
            "- VESTEL 50UA9631 50 inç 126 Ekran Uydu Alıcılı Smart 4K UHD Android LED TV Siyah Gri (Score: 0.729)\n",
            "- VESTEL 55UA9631 55 inç 139 Ekran Dahili Uydu Alıcılı 4K Android TV (Score: 0.724)\n",
            "- VESTEL 58UA9631 58 inç 146 Ekran Dahili Uydu Alıcılı 4K Android TV (Score: 0.722)\n",
            "- GRUNDIG 75 GHU 8500 A 75 inç 189 Ekran Uydu Alıcılı Google Smart 4K Ultra HD LED TV Antrasit (Score: 0.718)\n",
            "- VESTEL 70UA9630 70 inç 177 Ekran Uydu Alıcılı Smart 4K UHD Android TV Siyah (Score: 0.717)\n",
            "\n",
            "Query: telefon sarj aleti type c\n",
            "- APPLE USB-C VGA Çoklu Bağlantı Noktası Adaptörü MJ1L2ZM/A (Score: 0.844)\n",
            "- HAMA HM.135727 Adaptör USB-C Fiş VGA Soket  Full HD (Score: 0.838)\n",
            "- SANDISK iXpand Flash Drive 128GB Type A + Lightning Taşınabilir USB Bellek Gri (Score: 0.838)\n",
            "- SANDISK Ultra Shift USB 3.0 64GB USB Bellek (Score: 0.835)\n",
            "- SANDISK Extreme Go 256GB 3.2 USB Bellek (Score: 0.834)\n",
            "\n",
            "Query: gaming mouse rgb ışıklı\n",
            "- PHILIPS Sonicare Şarjlı Diş Fırçası 2'li Yedek Başlık - Siyah HX6062/13 (Score: 0.761)\n",
            "- TRUST 23728 Bigfoot XL Oyuncu Mouse Pad Siyah (Score: 0.759)\n",
            "- GOLDMASTER CAB-186 1.5m HDMI Kablo Siyah (Score: 0.749)\n",
            "- PHILIPS Sonicare Şarjlı Diş Fırçası 2'li Yedek Başlık  - Beyaz HX9022/10 (Score: 0.748)\n",
            "- S-LINK SLX-SATA150 HDD Poşetli Kablo (Score: 0.742)\n",
            "\n",
            "Query: bluetooth hoparlör taşınabilir\n",
            "- GRUNDIG Club Bluetooth Hoparlör Yeşil (Score: 0.554)\n",
            "- GOLDMASTER Neon X90 Kablosuz DJ Box (Score: 0.554)\n",
            "- GRUNDIG Club Bluetooth Hoparlör Siyah (Score: 0.551)\n",
            "- JBL Flip 6 Kablosuz Hoparlör Yeşil (Score: 0.543)\n",
            "- PHILIPS TAX5206 Bluetooth Parti Hoparlörü Parti Ișığı Siyah (Score: 0.541)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': {\n",
        "        'model_name': config.MODEL_NAME,\n",
        "        'embedding_dim': config.EMBEDDING_DIM\n",
        "    }\n",
        "}, 'model.pt')"
      ],
      "metadata": {
        "id": "-33j9LMH4Xng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save FAISS index\n",
        "import faiss\n",
        "index_path = 'faiss_index.index'\n",
        "faiss.write_index(search_engine.index, index_path)\n",
        "print(f\"FAISS index saved to: {index_path}\")"
      ],
      "metadata": {
        "id": "EbMBk4Ps5Aso",
        "outputId": "bcc55fd7-81b3-4b14-c165-618679eb7818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index saved to: faiss_index.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory in Google Drive\n",
        "import os\n",
        "save_dir = '/content/drive/MyDrive/monta'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save model state\n",
        "model_path = os.path.join(save_dir, 'model.pt')\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': {\n",
        "        'model_name': config.MODEL_NAME,\n",
        "        'embedding_dim': config.EMBEDDING_DIM,\n",
        "        'max_length': config.MAX_LENGTH\n",
        "    }\n",
        "}, model_path)\n",
        "\n",
        "# Save FAISS index\n",
        "import faiss\n",
        "index_path = os.path.join(save_dir, 'faiss_index.index')\n",
        "faiss.write_index(search_engine.index, index_path)\n",
        "\n",
        "# Copy products.json if needed\n",
        "import shutil\n",
        "json_path = os.path.join(save_dir, 'products.json')\n",
        "shutil.copy('products.json', json_path)\n",
        "\n",
        "# Verify files and sizes\n",
        "print(\"\\nSaved files in:\", save_dir)\n",
        "for filename in os.listdir(save_dir):\n",
        "    file_path = os.path.join(save_dir, filename)\n",
        "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "    print(f\"- {filename}: {size_mb:.2f} MB\")"
      ],
      "metadata": {
        "id": "h17hvqZ07dyY",
        "outputId": "aa86af88-116b-4024-b4f2-d3cbd6064d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved files in: /content/drive/MyDrive/monta\n",
            "- model.pt: 424.29 MB\n",
            "- faiss_index.index: 22.20 MB\n",
            "- products.json: 5.68 MB\n"
          ]
        }
      ]
    }
  ]
}